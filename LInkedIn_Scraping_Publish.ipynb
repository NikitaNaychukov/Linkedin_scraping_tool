{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code crawls aroung linkedin according to the list of your contacts supplied. It stores user information: name, company name, title, employement dates, school attended, field of study, study dates. This information gathered for each user crawled and stored into three separated relational tables: name, education, company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from datetime import date, datetime, timedelta\n",
    "from scrape_linkedin import ProfileScraper\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "from transliterate import translit\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import string\n",
    "import re        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions in use\n",
    "\n",
    "# Adds user names to the corresponding table\n",
    "def user_adder(user_id, personal_info):\n",
    "    \n",
    "    add_user = (\"INSERT INTO name \"\n",
    "               \"(id_name, name) \"\n",
    "               \"VALUES (%s, %s)\")\n",
    "    \n",
    "    RE = re.compile(u'[⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]', re.UNICODE)\n",
    "    \n",
    "    if personal_info['name'] is not None:\n",
    "        personal_info['name'] = RE.sub('', personal_info['name'])\n",
    "        if len(personal_info['name']) == 0:\n",
    "            personal_info['name'] = \"Chinese Name\"\n",
    "        if has_cyrillic(personal_info['name']):\n",
    "            personal_info['name'] = translit(personal_info['name'], \"ru\", reversed=True)\n",
    "    \n",
    "        personal_info['name'] = unidecode(personal_info['name'])\n",
    "    \n",
    "    personal_info['name'] = ['None' if v is None else v for v in [personal_info['name']]]\n",
    "    personal_info['name'] = ''.join(personal_info['name'])   \n",
    "    print(personal_info['name'])\n",
    "    data_user = (user_id, personal_info['name'])\n",
    "    \n",
    "    cursor.execute(add_user, data_user)\n",
    "    \n",
    "    cnx.commit()\n",
    "\n",
    "# Adds a company name, title, dates of employement to the corresponding table\n",
    "def companies_adder(user_id, list_of_jobs):\n",
    "    \n",
    "    for info_block in list_of_jobs:\n",
    "\n",
    "        add_company = (\"INSERT INTO company \"\n",
    "                   \"(id_name, company, title, date_from, date_to) \"\n",
    "                   \"VALUES (%s, %s, %s, %s, %s)\")\n",
    "        \n",
    "        if info_block['date_range'] is not None:\n",
    "            \n",
    "            if ('–' in info_block['date_range'] and 'Present' not in info_block['date_range']):\n",
    "                \n",
    "                date_time_str_from = info_block['date_range'].split('–')[0].rstrip()\n",
    "                if len(date_time_str_from) == 4:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%b %Y').date()\n",
    "\n",
    "                date_time_str_to = info_block['date_range'].split('–')[1].lstrip()\n",
    "                if len(date_time_str_to) == 4:\n",
    "                    date_time_obj_to = datetime.strptime(date_time_str_to, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_to = datetime.strptime(date_time_str_to, '%b %Y').date()\n",
    "                \n",
    "\n",
    "            if ('–' in info_block['date_range'] and 'Present' in info_block['date_range']):\n",
    "\n",
    "                date_time_str_from = info_block['date_range'].split('–')[0].rstrip()\n",
    "                if len(date_time_str_from) == 4:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%b %Y').date()\n",
    "\n",
    "                date_time_obj_to = str(date(2115, 1, 1))\n",
    "\n",
    "            if '–' not in info_block['date_range']:\n",
    "                \n",
    "                date_time_str_from = info_block['date_range']\n",
    "                if len(date_time_str_from) == 4:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%b %Y').date()\n",
    "                \n",
    "\n",
    "                date_time_obj_to = date_time_obj_from\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            date_time_obj_from = date.min\n",
    "            date_time_obj_to = date.min\n",
    "        \n",
    "        RE = re.compile(u'[⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]', re.UNICODE)\n",
    "        \n",
    "        if info_block['company'] is not None:\n",
    "            info_block['company']= RE.sub('', info_block['company'])\n",
    "            if has_cyrillic(info_block['company']):\n",
    "                info_block['company'] = translit(info_block['company'], \"ru\", reversed=True)\n",
    "            info_block['company'] = unidecode(info_block['company'])\n",
    "        \n",
    "        if info_block['title'] is not None:\n",
    "            info_block['title'] = RE.sub('', info_block['title'])\n",
    "            if has_cyrillic(info_block['title']):\n",
    "                info_block['title'] = translit(info_block['title'], \"ru\", reversed=True)\n",
    "            info_block['title'] = unidecode(info_block['title'])\n",
    "        \n",
    "        info_block['company'], info_block['title'], date_time_obj_from, date_time_obj_to = ['None' if v is None else v for v in [info_block['company'], \n",
    "                                                                                         info_block['title'], \n",
    "                                                                                         date_time_obj_from, \n",
    "                                                                                         date_time_obj_to]] \n",
    "        data_company = (user_id, info_block['company'], info_block['title'], date_time_obj_from, date_time_obj_to)\n",
    "\n",
    "        cursor.execute(add_company, data_company)\n",
    "\n",
    "    cnx.commit()\n",
    "\n",
    "# Adds education: school, field of study, dates attended \n",
    "def education_adder(user_id, list_of_edu):\n",
    "\n",
    "    for info_block in list_of_edu:\n",
    "\n",
    "        add_edu = (\"INSERT INTO education \"\n",
    "                   \"(id_name, school, field_of_study, date_from, date_to) \"\n",
    "                   \"VALUES (%s, %s, %s, %s, %s)\")\n",
    "        \n",
    "        if info_block['date_range'] is not None:\n",
    "        \n",
    "            if ('–' in info_block['date_range'] and 'Present' not in info_block['date_range']):\n",
    "\n",
    "                date_time_str_from = info_block['date_range'].split('–')[0].rstrip()\n",
    "                if len(date_time_str_from) == 4:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%b %Y').date()\n",
    "                \n",
    "\n",
    "                date_time_str_to = info_block['date_range'].split('–')[1].lstrip()\n",
    "                if len(date_time_str_to) == 4:\n",
    "                    date_time_obj_to = datetime.strptime(date_time_str_to, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_to = datetime.strptime(date_time_str_to, '%b %Y').date()\n",
    "                \n",
    "\n",
    "            if ('–' in info_block['date_range'] and 'Present' in info_block['date_range']):\n",
    "\n",
    "                date_time_str_from = info_block['date_range'].split('–')[0].rstrip()\n",
    "                if len(date_time_str_from) == 4:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%b %Y').date()\n",
    "\n",
    "                date_time_obj_to = str(date(2115, 1, 1))\n",
    "\n",
    "            if '–' not in info_block['date_range']:\n",
    "\n",
    "                date_time_str_from = info_block['date_range']\n",
    "                if len(date_time_str_from) == 4:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%Y').date()\n",
    "                else:\n",
    "                    date_time_obj_from = datetime.strptime(date_time_str_from, '%b %Y').date()\n",
    "\n",
    "                date_time_obj_to = date_time_obj_from\n",
    "                \n",
    "        else: \n",
    "            date_time_obj_from = date.min\n",
    "            date_time_obj_to = date.min\n",
    "        \n",
    "        RE = re.compile(u'[⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]', re.UNICODE)\n",
    "        \n",
    "        if info_block['name'] is not None:\n",
    "            info_block['name']= RE.sub('', info_block['name'])\n",
    "            if has_cyrillic(info_block['name']):\n",
    "                info_block['name'] = translit(info_block['name'], \"ru\", reversed=True)\n",
    "            info_block['name'] = unidecode(info_block['name'])\n",
    "        \n",
    "        if info_block['field_of_study'] is not None:\n",
    "            info_block['field_of_study'] = RE.sub('', info_block['field_of_study'])\n",
    "            if has_cyrillic(info_block['field_of_study']):\n",
    "                info_block['field_of_study'] = translit(info_block['field_of_study'], \"ru\", reversed=True)\n",
    "            info_block['field_of_study'] = unidecode(info_block['field_of_study'])\n",
    "        \n",
    "        info_block['name'], info_block['field_of_study'], date_time_obj_from, date_time_obj_to = ['None' if v is None else v for v in [info_block['name'], \n",
    "                                                                                                 info_block['field_of_study'], \n",
    "                                                                                                 date_time_obj_from, \n",
    "                                                                                                 date_time_obj_to]] \n",
    "        data_edu = (user_id, info_block['name'], info_block['field_of_study'], date_time_obj_from, date_time_obj_to)\n",
    "\n",
    "        cursor.execute(add_edu, data_edu)\n",
    "\n",
    "    cnx.commit()\n",
    "    \n",
    "def has_cyrillic(text):\n",
    "    return bool(re.search('[\\u0400-\\u04FF]', text))\n",
    "\n",
    "\n",
    "def cleaner(raw_list):\n",
    "    clean_names = []\n",
    "\n",
    "    emoji_pattern = re.compile(u\"[^\\U00000000-\\U0000d7ff\\U0000e000-\\U0000ffff]\", flags=re.UNICODE)\n",
    "\n",
    "    for name in raw_list:\n",
    "        \n",
    "\n",
    "        item = re.sub(r\" ?\\([^)]+\\)\", \"\", name)\n",
    "        item = emoji_pattern.sub(r'', item)\n",
    "        clean_names.append(item)\n",
    "    return clean_names\n",
    "\n",
    "def rawList(path):\n",
    "    \n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    name_list_raw = []\n",
    "    for i, j in data.iterrows(): \n",
    "\n",
    "        if type(j['First Name']) is str and type(j['Last Name']) is str:\n",
    "            name_list_raw.append(' '.join([j['First Name'],j['Last Name']]))\n",
    "    print(\"raw_list is formed\")\n",
    "    \n",
    "    return name_list_raw\n",
    "\n",
    "def extractNames(login, password, raw_list, PATH_TO_YOUR_LINKEDIN_PAGE):\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(PATH_TO_YOUR_LINKEDIN_PAGE)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"join-form\"]/p[3]/a').click()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    username = driver.find_element_by_id(\"login-email\")\n",
    "\n",
    "    username.send_keys(login)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    password_web = driver.find_element_by_id(\"login-password\")\n",
    "  \n",
    "    password_web.send_keys(password)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "    driver.find_element_by_id(\"login-submit\").click()\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "\n",
    "    c = 0\n",
    "    for raw_name in raw_list:\n",
    "\n",
    "        print(c, raw_name, \"is extracting\")\n",
    "        search = driver.find_element_by_xpath(\"//input[contains(@placeholder, 'Search')]\")\n",
    "\n",
    "        search.clear()\n",
    "        search.send_keys(raw_name)\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        search.send_keys(Keys.ENTER)\n",
    "\n",
    "        time.sleep(2)\n",
    "       \n",
    "        name = driver.find_elements_by_xpath(\"//a[contains(@data-control-name, 'search_srp_result')]\")[0].get_attribute(\"href\").split(\"/\")[-2]\n",
    "        time.sleep(0.5)\n",
    "        name_list_linkedin.append(name)\n",
    "        c += 1\n",
    "        \n",
    "    print(\"extraction is done\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db\n",
    "cnx = mysql.connector.connect(user='YOUR USER_NAME', password='YOUR_PASSWORD',\n",
    "                              host='YOUR HOST_IP',\n",
    "                              database='DB_NAME')\n",
    "cursor = cnx.cursor()\n",
    "print('Connection', cnx.is_connected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table initialization\n",
    "# Creates tables in yr database\n",
    "\n",
    "TABLES = {}\n",
    "TABLES['name'] = (\n",
    "    \"CREATE TABLE `name` (\"\n",
    "    \"  `id_name` int(11) NOT NULL,\"\n",
    "    \"  `name` varchar(100) NOT NULL,\"\n",
    "    \"  PRIMARY KEY (`id_name`)\"\n",
    "    \")\")\n",
    "\n",
    "TABLES['education'] = (\n",
    "    \"CREATE TABLE `education` (\"\n",
    "    \"  `id_edu` INT NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `id_name` int(11) NOT NULL,\"\n",
    "    \"  `school` varchar(100),\"\n",
    "    \"  `field_of_study` varchar(100),\"\n",
    "    \"  `date_from` date,\"\n",
    "    \"  `date_to` date,\"\n",
    "    \"  PRIMARY KEY (`id_edu`),\"\n",
    "    \"  CONSTRAINT `fk_edu_to_names` FOREIGN KEY (`id_name`) \"\n",
    "    \"     REFERENCES `name` (`id_name`) ON DELETE CASCADE ON UPDATE CASCADE)\"\n",
    "    )\n",
    "\n",
    "TABLES['company'] = (\n",
    "    \"CREATE TABLE `company` (\"\n",
    "    \"  `id_comp` INT NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `id_name` int(11) NOT NULL,\"  \n",
    "    \"  `company` varchar(100),\"\n",
    "    \"  `title` varchar(100),\"\n",
    "    \"  `date_from` date ,\"\n",
    "    \"  `date_to` date ,\"\n",
    "    \"  PRIMARY KEY (`id_comp`),\"\n",
    "    \"  CONSTRAINT `fk_comp_to_names` FOREIGN KEY (`id_name`) \"\n",
    "    \"     REFERENCES `name` (`id_name`) ON DELETE CASCADE ON UPDATE CASCADE)\"\n",
    "    )\n",
    "\n",
    "for table_name in TABLES:\n",
    "    desc = TABLES[table_name]\n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(table_name), end='')\n",
    "        cursor.execute(desc)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(\"already exists.\")\n",
    "        else:\n",
    "            print(desc)\n",
    "            print(err.msg)\n",
    "    else:\n",
    "        print(\"OK\")\n",
    "cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. download list of connections from linkedin\n",
    "# 2. set a path to a csv file with connections\n",
    "# 3. set your login and password\n",
    "\n",
    "path = \"YOUR PATH TO CSV\"\n",
    "login = 'your_login'\n",
    "password = \"your_password\"\n",
    "\n",
    "name_list_linkedin = []\n",
    "name_list_raw = rawList(path)\n",
    "name_list_raw_clean = cleaner(name_list_raw)\n",
    "\n",
    "PATH_TO_YOUR_LINKEDIN_PAGE = \"https://www.linkedin.com/in/YOUR_USER_NAME/\"\n",
    "\n",
    "extractNames(login, password, name_list_raw_clean, PATH_TO_YOUR_LINKEDIN_PAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out prepared names to txt for further use\n",
    "PATH_TO_STORED_NAMELIST = \"YOUR_PATH\"\n",
    "with open(PATH_TO_STORED_NAMELIST, \"w\") as MyFile: # Use file to refer to the file object\n",
    "    for element in name_list_linkedin:\n",
    "        MyFile.write(element)\n",
    "        MyFile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read prepared names to python list for tranfer to main function of extraction from linkedin to DB\n",
    "name_list_linkedin = []\n",
    "\n",
    "PATH_TO_STORED_NAMELIST = \"YOUR_PATH\"\n",
    "\n",
    "with open(PATH_TO_STORED_NAMELIST, \"r\") as MyFile: # Use file to refer to the file object\n",
    "    for name in MyFile:\n",
    "        name_list_linkedin.append(name.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.\n",
    "# Install from source\n",
    "# git clone https://github.com/austinoboyle/scrape-linkedin-selenium.git\n",
    "# Run python setup.py install\n",
    "\n",
    "# 1.\n",
    "# Getting LI_AT\n",
    "# 1.Navigate to www.linkedin.com and log in\n",
    "# 2.Open browser developer tools (Ctrl-Shift-I or right click -> inspect element)\n",
    "# 3.Select the appropriate tab for your browser (Application on Chrome, Storage on Firefox)\n",
    "# 4.Click the Cookies dropdown on the left-hand menu, and select the www.linkedin.com option\n",
    "# 5.Find and copy the li_at value\n",
    "\n",
    "# 2.\n",
    "# download chromedriver and set the path as below\n",
    "# driver = webdriver.Chrome(YOUR_PATH)\n",
    "\n",
    "\n",
    "user_list = name_list_linkedin\n",
    "\n",
    "#calculate current rows in the table name\n",
    "cursor.execute(\"select count(*) from name\")\n",
    "n = cursor.fetchone()\n",
    "n = n[0]\n",
    "\n",
    "#main process of uploading to DB\n",
    "with ProfileScraper(cookie='YOUR_LIAT') as scraper:\n",
    "    print('uploaded before', n)\n",
    "    \n",
    "    for user_id in range(len(user_list)):\n",
    "#         try:\n",
    "        print('this number is', user_id+n+1, user_list[user_id])\n",
    "        print('retrieve from linkedin')\n",
    "        profile = scraper.scrape(user=user_list[user_id])\n",
    "\n",
    "        user_adder(user_id+n+1, profile.personal_info)\n",
    "        print('upload user name to DB')\n",
    "        companies_adder(user_id+n+1, profile.experiences['jobs'])\n",
    "        print('upload jobs name to DB')\n",
    "        education_adder(user_id+n+1, profile.experiences['education'])\n",
    "        print('upload education name to DB')\n",
    "#         except:\n",
    "#             continue\n",
    "            \n",
    "        time.sleep(5)\n",
    "        \n",
    "print('done')\n",
    "# print (profile.experiences.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close connections\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
